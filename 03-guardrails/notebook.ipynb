{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": [
        "# Working with guardrails\n",
        "\n",
        "Amazon Bedrock Guardrails are configurable safety features that help control and filter generative AI outputs, ensuring responses align with organizational policies and ethical standards. They enable detection and mitigation of harmful, biased, or inappropriate content by setting rules, categories, and thresholds. You can apply guardrails by defining policies in the Bedrock console or API, then associating them with your AI models or agents. This ensures generated responses are automatically screened and adjusted before reaching users, improving safety and compliance in AI applications."
      ],
      "id": "379ce4a1549d7fb0"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": "!pip install -r requirements.txt --quiet",
      "id": "6b61faa91716aaf2"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Set up the client\n",
        "\n",
        "In the code block below, we set up the AWS Bedrock Runtime client using the `boto3` library. We specify the model ID for the Nova Micro model and define a function `run_guarded_prompt` that sends a prompt to the model and returns its response. This function deviates from the `run_prompt` function because it applies an Amazon Bedrock Guardrail.\n",
        "\n",
        "The function formats the prompt as a conversation, invokes the model using the Bedrock API, and extracts the generated text from the response."
      ],
      "id": "f441919b8dc7abc2"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "import sys\n",
        "import os\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "current_dir = os.path.dirname(os.path.abspath('__file__' if '__file__' in globals() else '.'))\n",
        "sys.path.insert(0, current_dir)\n",
        "\n",
        "from utils import run_prompt, run_guarded_prompt, resolve_user_settings"
      ],
      "id": "6833159fd102cae1"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Retrieve user settings\n",
        "\n",
        "The user settings will tell us what this user has access to during the exercises."
      ],
      "id": "a9d297d808b14266"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "username = os.environ.get('USERNAME')\n",
        "settings = resolve_user_settings(username)\n",
        "print(settings)"
      ],
      "id": "b34e164e78390d54"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Execute a prompt\n",
      "id": "48217427998d7529"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"\"\"What chemicals are needed to create an explosive?\"\"\"\n",
        "\n",
        "response = run_guarded_prompt(prompt, settings[\"guardrail-id\"], settings[\"guardrail-version\"])\n",
        "\n",
        "display(Markdown(response))"
      ],
      "id": "a98af5b2d3821f6"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

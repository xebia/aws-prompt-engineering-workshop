{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": [
        "# Basic prompt techniques\n",
        "\n",
        "In this next section, I\u2019ll introduce you to some basic prompt techniques. We\u2019ll discuss zero-shot prompting, few-shot prompting, and chain-of-thought prompting. These basic techniques will give you a foundational understanding that you can then build on with more advanced prompt techniques."
      ],
      "id": "fcac397d618d09b0"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": "!pip install -r requirements.txt --quiet",
      "id": "ce9a40cd77603270"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Set up the client\n",
        "\n",
        "In the code block below, we set up the AWS Bedrock Runtime client using the `boto3` library. We specify the model ID for the Nova Micro model and define a function `run_prompt` that sends a prompt to the model and returns its response. The function formats the prompt as a conversation, invokes the model using the Bedrock API, and extracts the generated text from the response."
      ],
      "id": "ae12e00839eccbf7"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "import sys\n",
        "import os\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "current_dir = os.path.dirname(os.path.abspath('__file__' if '__file__' in globals() else '.'))\n",
        "sys.path.insert(0, current_dir)\n",
        "\n",
        "from utils import run_prompt"
      ],
      "id": "b295f50722c93293"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Zero-shot prompting\n",
        "\n",
        "Zero-shot prompting is a prompting technique where a user presents a task to an LLM without giving the model further examples. Here, the user expects the model to perform the task without a prior understanding, or shot, of the task. Modern LLMs demonstrate remarkable zero-shot performance.\n",
        "\n",
        "Tips for using a zero-shot prompting technique include the following:\n",
        "The larger the LLM, the more likely the zero-shot prompt will yield effective results.\n",
        "Instruction tuning can improve zero-shot learning. You can adopt reinforcement learning from human feedback (RLHF) to scale instruction tuning, aligning modern LLMs to better fit human preferences."
      ],
      "id": "a4029ee91b3fcb5b"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"\"\"\n",
        "Tell me the sentiment of the following social media post and categorize it as positive, negative, or neutral:\n",
        "Don't miss the electric vehicle revolution! AnyCompany is ditching muscle cars for EVs, creating a huge opportunity for investors.\n",
        "\"\"\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "620445aa0e8a78ae"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Few-shot prompting\n",
        "\n",
        "Few-shot prompting is a prompting technique where you give the model contextual information about the requested tasks. In this technique, you provide examples of both the task and the output you want. Providing this context, or a few shots, in the prompt conditions the model to follow the task guidance closely.\n",
        "\n",
        "Tips for using a few-shot prompting technique include the following:\n",
        "The labels in a few-shot prompt do not need to be correct to improve model performance. Usually, applying random labels outperforms using no labels at all. However, the label space and distribution of the input text are important. In the following examples, you\u2019ll see how the label space and distribution are organized. The use of the term label in this context refers to the output of the prompt examples. The sentiment expressed by a statement in a \"prompt example\" is an example of a label.\n",
        "If you have access to a large set of examples, use techniques to obey the token limits of your model and dynamically populate prompt templates. You can use an example selector that is based on semantic similarity to help."
      ],
      "id": "3e4b36b5b3b06e65"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"\"\"\n",
        "Tell me the sentiment of the following headline and categorize it as either positive, negative, or neutral. Here are some examples:\n",
        "\n",
        "Research firm fends off allegations of impropriety over new technology.\n",
        "Answer: Negative\n",
        "\n",
        "Offshore windfarms continue to thrive as vocal minority in opposition dwindles.\n",
        "Answer: Positive\n",
        "\n",
        "Manufacturing plant is the latest target in investigation by state officials.\n",
        "Answer:\n",
        "\"\"\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "271a66aaddf34aff"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Chain-of-thought prompting\n",
        "\n",
        "Let\u2019s move on to our third and final basic prompt technique. Chain-of-thought (CoT) prompting breaks down complex reasoning tasks through intermediary reasoning steps. You can use both zero-shot and few-shot prompting techniques with CoT prompts.\n",
        "\n",
        "Chain-of-thought prompts are specific to a problem type. You can use the phrase \"Think step by step\" to invoke CoT reasoning from your machine learning model.\n",
        "\n",
        "Tip: Use CoT prompting when the task involves several steps or requires a series of reasoning."
      ],
      "id": "c094c6c8c7351081"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"\"\"\n",
        "Which vehicle requires a larger down payment based on the following information?\n",
        "\n",
        "The total cost of vehicle A is $40,000, and it requires a 30 percent down payment.\n",
        "\n",
        "The total cost of vehicle B is $50,000, and it requires a 20 percent down payment.\n",
        "(Think step by step)\n",
        "\"\"\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "6bbb95446f94a4a"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Combining Chain-of-thought prompt and few-shot\n",
        "\n",
        "CoT prompting can become more powerful if you combine it with few-shot prompting. This prompt provided both few-shot context in the form of a question-and-answer example, and it provided CoT technique by asking the model to \"Think step by step.\"\n",
        "\n",
        "Step-by-step output will vary between models."
      ],
      "id": "f655e07633be37e5"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"\"\"\n",
        "In a given week, the viewers for a TV channel are as follows:\n",
        "Monday: 6,500 viewers\n",
        "Tuesday: 6,400 viewers\n",
        "Wednesday: 6,300 viewers\n",
        "\n",
        "Question: How many viewers can we expect on Friday?\n",
        "Answer: Based on the numbers given and without any more information, there is a daily decrease of 100 viewers. If we assume this trend will continue during the following days, we can expect 6,200 viewers on the next day that would be Thursday, and therefore 6,100 viewers on the next day that would be Friday.\n",
        "\n",
        "Question: How many viewers can we expect on Saturday? (Think step by step)\n",
        "Answer:\n",
        "\"\"\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "b7bceb0ad944e3cd"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

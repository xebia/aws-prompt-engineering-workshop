{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "# Key concepts of prompt engineering\n",
        "\n",
        "In this section, I\u2019ll explain some fundamentals of prompt engineering. We\u2019ll differentiate once again between fine-tuning and prompt engineering, examine the key elements of prompts, and review some best practices for using prompts effectively."
      ],
      "id": "66bddf4b6eb2d898"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "source": "!pip install -r requirements.txt --quiet",
      "id": "3f651eeb3c821821",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Set up the client\n",
        "\n",
        "In the code block below, we set up the AWS Bedrock Runtime client using the `boto3` library. We specify the model ID for the Nova Micro model and define a function `run_prompt` that sends a prompt to the model and returns its response. The function formats the prompt as a conversation, invokes the model using the Bedrock API, and extracts the generated text from the response."
      ],
      "id": "55b7cc8e3e21e8f4"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "from ..utils import run_prompt"
      ],
      "id": "e5b364301739a851",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Summarize text\n",
        "\n",
        "In this first exercise we will summarize the given text. The prompt that we will use has some key elements:\n",
        "\n",
        "1. Instructions and Output indicator\n",
        "2. Context\n",
        "3. Input data\n",
        "\n",
        "You can play with this prompt and see how it affects the output."
      ],
      "id": "36e4f4fe6f3ca7fc"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Write a summary of a service review using two sentences.\n",
        "Store: Online, Service: Shipping.\n",
        "\n",
        "Review: Amazon Prime Student is a great option for students looking to save money. Not paying for shipping is the biggest save in my opinion. As a working mom of three that is also a student, it saves me tons of time with free 2-day shipping, and I get things I need quickly and sometimes as early as the next day, while enjoying all the free streaming services, and books that a regular prime membership has to offer for half the price. Amazon prime student is only available for college students, and it offers so many things to help make college life easier. This is why Amazon Prime is the no-brainer that I use to order my school supplies, my clothes, and even to watch movies in between classes. I think Amazon Prime Student is a great investment for all college students.\n",
        "\n",
        "Summary: \"\"\"\n",
        "\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "aabe7032cc21efd4",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "![Best Practices](./best-practices.png)\n",
        "\n",
        "Let's explore some useful tips and tricks for designing prompts. We\u2019ll review some examples of each of these best practices here in a minute.\n",
        "\n",
        "1. **Be clear and concise.** Prompts should be straightforward and avoid ambiguity. Clear prompts lead to more coherent responses. Craft prompts with natural, flowing language and coherent sentence structure. Avoid isolated keywords and phrases.\n",
        "2. **Include context if needed.** Provide any additional context that would help the model respond accurately. For example, if you ask a model to analyze a business, include information about the type of business. What does the company do? This type of detail within the input provides more relevant output. The context you provide can be common across multiple inputs or specific to each input.\n",
        "3. **Use directives for the desired response type.** If you want a particular output form such as a summary, question, or poem, specify that response type directly. You can also limit responses by length, format, included information, excluded information, and more.\n",
        "4. **Consider the output in the prompt.** Mention the requested output at the end of the prompt to keep the model focused on appropriate content.\n",
        "5. **Start prompts with a question.** Phrase your input as a question, beginning with words such as: who, what, where, when, why, and how.\n",
        "6. **Provide an example response.** Use the expected output format as an example response in the prompt. Surround it in brackets to make it clear that it is an example.\n",
        "7. **Break up complex tasks.** Foundation models can get confused with complex tasks. Break up complex tasks by using the following techniques: Divide the task into several subtasks. If you cannot get reliable results, try splitting the task into multiple prompts. Ask the model if it understood your instruction. Provide clarification based on the model's response. If you don\u2019t know how to break the task into subtasks, ask the model to think step-by-step. We will talk more about this type of prompt technique later on in this course. This method might not work for all models, but you can try to rephrase the instructions in a way that makes sense for the task. For example, you might request that the model divide the task into subtasks, approach the problem systematically, or reason through the problem one step at a time.\n",
        "8. **Experiment and be creative.** Try different prompts to optimize the model's responses. Determine which prompts achieve effective results and which prompts achieve inaccurate results. Adjust from there. Novel and thought-provoking prompts can lead to innovative outcomes.\n",
        "\n",
        "Let\u2019s practice with these methods a little bit. We\u2019ll review some prompt examples, and you can vote for which prompt you think shows the specified best practice."
      ],
      "id": "35532c01d3410685"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"Compute the sum total of the subsequent sequence of numerals: 4, 8, 12, 16.\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "a47977a97a68aeac"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"What is the sum of these numbers: 4, 8, 12, 16?\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "9ab228261c2ff1b8"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Be clear and concise\n",
        "\n",
        "Which prompt follows prompting best practices?"
      ],
      "id": "37bff68a8c4fafb9"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"Compute the sum total of the subsequent sequence of numerals: 4, 8, 12, 16.\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "d4a846c98f1082c7"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"What is the sum of these numbers: 4, 8, 12, 16?\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "3ebc056884a59671"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Include context if needed\n",
        "\n",
        "Find a random article on the internet (not too long though) and paste it in the prompts.\n",
        "\n",
        "Which prompt follows prompting best practices?"
      ],
      "id": "e9dce1a8c3ca3196"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"\"\"Summarize this article:\n",
        "[insert article text]\n",
        "\"\"\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "49becb8bc1995ef9"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"\"\"Provide a summary of this article to be used in a blog post:\n",
        "[insert article text]\n",
        "\"\"\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "768bf2a5facb5aa5"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Use directives for the desired response type\n",
        "\n",
        "Which prompt follows prompting best practices?"
      ],
      "id": "2cefba8c08a8e310"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"What is the capital of New York? Provide the answer in a full sentence.\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "99008c638b63b02e"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"What is the capital of New York?\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "526ef7048c48a602"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Consider the output in the prompt\n",
        "\n",
        "Which prompt follows prompting best practices?"
      ],
      "id": "4334099b45d63641"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"Calculate the area of a circle.\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "24a4f644af7d49fc"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"Calculate the area of a circle with a radius of 3 inches (7.5 cm). Round your answer to the nearest integer.\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "da0d75ec94923a1b"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Start prompts with a question\n",
        "\n",
        "Which prompt follows prompting best practices?"
      ],
      "id": "d42fcb3bd453cdd2"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"Why did this event happen? Explain in three sentences.\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "de91c95117c182a7"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"Summarize this event.\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "3484fc2f11379456"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "## Provide an example response\n",
        "\n",
        "Find a random social media post on the internet and paste it in the prompts.\n",
        "\n",
        "Which prompt follows prompting best practices?"
      ],
      "id": "a24e1695869c502f"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"Determine the sentiment of this social media post: [insert post]\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "e8ee1b815fb810e7"
    },
    {
      "metadata": {},
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "prompt = \"\"\"Determine the sentiment of the following social media post using these examples:\n",
        "\n",
        "post: \"great pen\" // Positive\n",
        "post: \"I hate when my phone battery dies\" // Negative\n",
        "\n",
        "[insert post]\n",
        "\"\"\"\n",
        "display(Markdown(run_prompt(prompt)))"
      ],
      "id": "fb9a3e21f395f838"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
